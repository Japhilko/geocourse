set.seed(323)
n <- 100
spatsamp <- spsample(plz[plz@data$PLZ99=="68239",], n,type="random")
spatlist <- list()
for (i in 1:n){
spatlist[[i]] <- ggmap::revgeocode(c(spatsamp[i,]$x,spatsamp[i,]$y))
}
spatlist
setwd("D:/github/geocourse/slides")
spatvec <- unlist(spatlist)
spatvec
spatsamp$adress <- spatvec
spatsamp
save(spatsamp,file="../data/spatsamp_68239.RData")
install.packages("geojsonR")
citation("geojsonR")
install.packages("lawn")
library(lawn)
setwd("slides")
nycounties <- geojsonio::geojson_read("../data/Amsterdam_bus_stop.geojson",
what = "sp")
bus_stops <- geojsonio::geojson_read("../data/Amsterdam_bus_stop.geojson",
what = "sp")
plot(bus_stops)
sp::plot(bus_stops)
gcs <- geojsonio::geojson_read("http://nominatim.openstreetmap.org/search?format=json&addressdetails=1&extratags=1&q=Amsterdam+Niederlande+Rozengracht+1",what="sp")
firstpart <- "http://overpass-api.de/api/interpreter?data="
paste0(firstpart,"node["name"="Gielgen"](50.7,7.1,50.8,7.2);out;")
paste0(firstpart,"node['name'='Gielgen'](50.7,7.1,50.8,7.2);out;'")
gcs <- geojsonio::geojson_read(paste0(firstpart,"node['name'='Gielgen'](50.7,7.1,50.8,7.2);out;",
what="sp")
gcs <- geojsonio::geojson_read(firstpart,"node['name'='Gielgen'](50.7,7.1,50.8,7.2);out;",
what="sp")
gr_polygon(n = 1, vertices = 5, max_radial_length = 5)
a <- gr_polygon(n = 1, vertices = 5, max_radial_length = 5)
plot(a)
view(a)
gcs <- geojsonio::geojson_read(paste0(firstpart,"node['name'='Gielgen'](50.7,7.1,50.8,7.2);out;",
what="sp"))
?geojson_read
gcs <- geojsonio::geojson_read(paste0(firstpart,"node['name'='Gielgen'](50.7,7.1,50.8,7.2);out;",
what="sp",method="web"))
data_path <- "D:/GESIS/data/"
library(rgdal)
setwd(data_path)
plz <- readOGR ("post_pl.shp","post_pl")
ddat <- unionSpatialPolygons(SpP = plz,
IDs = rep(1,length(plz)))
library(maptools)
ddat <- unionSpatialPolygons(SpP = plz,
IDs = rep(1,length(plz)))
set.seed(323)
n <- 1000
spatsamp <- spsample(ddat,n,type="random")
library(ggmap)
spatlist <- list()
for (i in 1:n){
spatlist[[i]] <- ggmap::revgeocode(c(spatsamp[i,]$x,
spatsamp[i,]$y))
}
spatvec <- unlist(spatlist)
spatvec
getwd()
setwd("D:/github/geocourse/slides")
plz_place <- "Deutschland"
save(spatsamp,file=paste0("../data/spatsamp_",plz_place,".RData"))
plot(ddat)
points(spatsamp)
addr_list <- spatsamp$adress
spatsamp
addr_list
spatsamp$adress <- spatvec
plz_place <- "Deutschland"
save(spatsamp,file=paste0("../data/spatsamp_",plz_place,".RData"))
points(spatsamp)
addr_list <- spatsamp$adress
indna <- which(is.na(addr_list))
addr_list <- as.character(addr_list)
addr_list2 <- strsplit(x = addr_list,split = " ")
addr_list2b <- unlist(lapply(addr_list2,length))
ind_ua <- which(addr_list2b<3)
addr_list3 <- unlist(lapply(addr_list2,function(x)x[1]))
# Adressen rauß nehmen, die Landstraßen
# oder Autobahnen sind
addr_list3 <- tolower(addr_list3)
ind_str <- grep("^[a-z][1-9]", addr_list3, value = F)
addr_list_t <- addr_list[-c(ind_str,ind_ua,indna)]
addr_list_t
ind_str2 <- grep("Unnamed Road", addr_list3, value = F)
addr_list <- spatsamp$adress
# Adressen raus nehmen, die NA sind
indna <- which(is.na(addr_list))
addr_list <- as.character(addr_list)
addr_list2 <- strsplit(x = addr_list,split = " ")
addr_list2b <- unlist(lapply(addr_list2,length))
ind_ua <- which(addr_list2b<3)
addr_list3 <- unlist(lapply(addr_list2,function(x)x[1]))
# Adressen rauß nehmen, die Landstraßen
# oder Autobahnen sind
addr_list3 <- tolower(addr_list3)
ind_str <- grep("^[a-z][1-9]", addr_list3, value = F)
ind_str2 <- grep("Unnamed Road", addr_list3, value = F)
addr_list_t <- addr_list[-c(ind_str,ind_str2,ind_ua,indna)]
addr_list_t
addr_list <- spatsamp$adress
# Adressen raus nehmen, die NA sind
indna <- which(is.na(addr_list))
addr_list <- as.character(addr_list)
addr_list2 <- strsplit(x = addr_list,split = " ")
addr_list2b <- unlist(lapply(addr_list2,length))
ind_ua <- which(addr_list2b<3)
addr_list3 <- unlist(lapply(addr_list2,function(x)x[1]))
# Adressen rauß nehmen, die Landstraßen
# oder Autobahnen sind
addr_list3 <- tolower(addr_list3)
ind_str <- grep("^[a-z][1-9]", addr_list3, value = F)
ind_str2 <- agrep("Unnamed Road", addr_list3, value = F)
addr_list_t <- addr_list[-c(ind_str,ind_str2,ind_ua,indna)]
addr_list_t
addr_list <- spatsamp$adress
# Adressen raus nehmen, die NA sind
indna <- which(is.na(addr_list))
addr_list <- as.character(addr_list)
addr_list2 <- strsplit(x = addr_list,split = " ")
addr_list2b <- unlist(lapply(addr_list2,length))
ind_ua <- which(addr_list2b<3)
addr_list3 <- unlist(lapply(addr_list2,function(x)x[1]))
# Adressen rauß nehmen, die Landstraßen
# oder Autobahnen sind
addr_list3 <- tolower(addr_list3)
ind_str <- grep("^[a-z][1-9]", addr_list3, value = F)
ind_str2 <- agrep("unnamed road", addr_list3, value = F)
addr_list_t <- addr_list[-c(ind_str,ind_str2,ind_ua,indna)]
addr_list_t
ind_str2
addr_list3
addr_list <- spatsamp$adress
# Adressen raus nehmen, die NA sind
indna <- which(is.na(addr_list))
addr_list <- as.character(addr_list)
addr_list2 <- strsplit(x = addr_list,split = " ")
addr_list2b <- unlist(lapply(addr_list2,length))
ind_ua <- which(addr_list2b<3)
addr_list3 <- unlist(lapply(addr_list2,function(x)x[1]))
# Adressen rauß nehmen, die Landstraßen
# oder Autobahnen sind
addr_list3 <- tolower(addr_list3)
ind_str <- grep("^[a-z][1-9]", addr_list3, value = F)
ind_str2 <- agrep("unnamed", addr_list3, value = F)
addr_list_t <- addr_list[-c(ind_str,ind_str2,ind_ua,indna)]
addr_list_t
save(addr_list_t,file=paste0("../data/addr_list_t_",plz_place,"_samp1",".RData"))
# set.seed(323)
set.seed(5)
n <- 1000
spatsamp <- spsample(ddat,n,type="random")
library(ggmap)
library(leaflet)
library(magrittr)
m <- leaflet() %>%
addTiles() %>%
addMarkers(lng=4.891013, lat=52.38054, popup="Amsterdam")
m
library(ggmap)
gc_ma <- geocode("GESIS Mannheim")
gc_ma
gc_tma <- geocode_OSM("Mannheim, GESIS")
library("tmaptools")
gc_tma <- geocode_OSM("Mannheim, GESIS")
gc_tma
library(leaflet)
library(magrittr)
m <- leaflet() %>%
addTiles() %>%
addMarkers(lng=8.463061 , lat=49.485736 , popup="GESIS Mannheim")
m
?gr_polygon
ab <- lawn_polygon(ddat)
geojson_write(ddat, file = "../data/ddat.geojson")
library(geojsonio)
geojson_write(ddat, file = "../data/ddat.geojson")
dland <- geojsonio::geojson_read("../data/ddat.geojson",
what = "sp")
view(dland)
sp::plot(bus_stops)
sp::plot(dland)
?geojson_read
lawn_data
view(lawn_data)
view(lawn_data$points_average)
gcs <- geojsonio::geojson_read("../data/ddat.geojson")
view(gcs)
citation("lawn")
b <- gr_polygon(n = 1)
view(b)
library(jsonlite)
con <- url("http://nominatim.openstreetmap.org/search?format=json&
addressdetails=1&extratags=1&q=Amsterdam+Niederlande+Rozengracht+1")
geoc <- read_json(paste(readLines(con,warn=F),
collapse = ''))
geoc <- read_json("../data/ddat.geojson")
citation("jsonlite")
devtools::install_github("ropensci/bbox") # https://github.com/ropensci/PostcodesioR/
b_box(ddat)
library(bbox)
b_box(ddat)
citation("bbox")
mutate_geocode("Mannheim")
?mutate_geocode
df <- data.frame(
address = c("1600 Pennsylvania Avenue, Washington DC", "", "houston texas"),
stringsAsFactors = FALSE
)
df
(load("../data/addr_list_t_Deutschland_samp1.RData"))
head(addr_list_t)
addr_dat <- data.frame(address = addr_list_t)
gc_addr <- mutate_geocode(df, address)
gc_addr <- mutate_geocode(addr_dat, address)
geocode("Dorsten")
geocode("Heidelberg")
library(mapview)
load("../data/spatsamp_68239.RData")
spatsamp
mapview(spatsamp)
crs(spatsamp)
library(rgdal)
crs(spatsamp)
library(raster)
crs(spatsamp)
?geocode_OSM
date()
getwd()
save(ddat,file="../data/ddat.RData")
geocode("Heidelberg")
geocode("Trier")
geocode("")
geocode_OSM(addr_list_t[1])
gc_info<-opencage_forward(placename =
"Amsterdam, Van Woustraat")
library(opencage)
gc_info<-opencage_forward(placename =
"Amsterdam, Van Woustraat")
cat("OPENCAGE_KEY=a15574982f204f19844db68a4dcaad6b\n",
file=file.path(normalizePath("~/"), ".Renviron"),
append=TRUE)
gc_info<-opencage_forward(placename =
"Amsterdam, Van Woustraat")
library(geonames)
install.packages("geonames")
library(geonames)
options(geonamesUsername="Japhilko")
GNfindNearbyWikipedia(postalcode=8775,country="CH",radius=10)
GNfindNearbyWikipedia(postalcode=8775,country="CH",radius=10)
MAwiki <- GNfindNearbyWikipedia(postalcode=68239,country="DE",radius=10)
MAwiki
save(MAwiki,file="../data/MAwiki.RData")
load("../data/MAwiki.RData")
library(knitr)
BBT <- qmap("Berlin Brandenburger Tor")
BBT
dev.off()
BBT
getwd()
pdf("figure/BBT_ggmap.pdf")
BBT
dev.off()
ham_map <- qmap('Hamburg', zoom = 20, maptype="hybrid")
save(ham_map,file="../data/ham_map.RData")
pdf("figure/ham_map.pdf")
ham_map
dev.off()
png("figure/ham_map.png")
ham_map
dev.off()
ham_map_sat <- qmap('Hamburg', zoom = 14, maptype="satellite")
save(ham_map_sat,file="../data/ham_map_sat.RData")
pdf("figure/ham_map_sat.pdf")
ham_map_sat
dev.off()
png("figure/ham_map_sat.png")
ham_map_sat
dev.off()
ham_map_sat <- qmap('Hamburg', zoom = 14, maptype="satellite")
save(ham_map_sat,file="../data/ham_map_sat.RData")
ham_map_sat
getwd()
pdf("figure/ham_map_sat.pdf")
ham_map_sat
dev.off()
png("figure/ham_map_sat.png")
ham_map_sat
dev.off()
ham_map_z20 <- qmap('Mannheim', zoom = 13)
save(ham_map_sat,file="../data/ham_map_sat.RData")
pdf("figure/ham_map_z20.pdf")
ham_map_z20
dev.off()
png("figure/ham_map_z20.png")
ham_map_z20
dev.off()
ham_map_z20 <- qmap('Mannheim', zoom = 13)
save(ham_map_sat,file="../data/ham_map_sat.RData")
pdf("figure/ham_map_z20.pdf")
ham_map_z20
dev.off()
png("figure/ham_map_z20.png")
ham_map_z20
dev.off()
germany <- qmap("Germany")
save(germany,file="../data/germany.RData")
pdf("figure/germany.pdf")
germany
dev.off()
png("figure/germany.png")
germany
dev.off()
germany <- qmap("Germany")
save(germany,file="../data/germany.RData")
pdf("figure/germany.pdf")
germany
dev.off()
png("figure/germany.png")
germany
dev.off()
Berchtesgarden <- qmap('Berchtesgarden', zoom = 14,
maptype="terrain")
Schriesheim <- qmap('Schriesheim', zoom = 14,
maptype="terrain")
vg250path <- "D:/GESIS/data/vg250_3112.utm32s.shape.ebenen/vg250_ebenen"
library(rgdal)
setwd(vg250path)
VG250 <- readOGR ("VG250_GEM.shp","VG250_GEM")
bla <- substr(VG250@data$AGS_0,1,2)
plot(VG250[bla=="11",])
ham_map_z12 <- qmap("Hamburg", zoom = 12)
date()
getwd()
setwd("D:/github/geocourse")
main_path <- "D:/github/geocourse"
slide_path <- paste0(main_path,"slides/")
rcode_path <- paste0(main_path,"rcode/")
dirnamen <- dir()
dirnamen
#-------------------------------------------------#
# Parts of the presentation
#-------------------------------------------------#
setwd(slide_path)
dirnamen <- dir()
main_path <- "D:/github/geocourse"
main_path <- "D:/github/geocourse/"
slide_path <- paste0(main_path,"slides/")
rcode_path <- paste0(main_path,"rcode/")
#-------------------------------------------------#
# Parts of the presentation
#-------------------------------------------------#
setwd(slide_path)
dirnamen <- dir()
dirnamen
presparts <- dirnamen[grep(".Rmd",dirnamen)]
presparts
# setwd("D:/gitlab/IntroDataAnalysis/rcode/")
setwd(rcode_path)
for (i in 1:length(presparts)){
purl(paste0("../slides/",presparts[i]),documentation = 2)
}
presparts
i
length(presparts)
install.packages("choroplethr")
install.packages("choroplethrMaps")
vec_a <- c("A",2,6,1,"C")
vec_b <- c(1,"C",2)
match(vec_a,vec_b)
data(land)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE,warning=F,cache=T,fig.height=4)
# Chunk 2
library(knitr)
library(DT)
Ex <- T
# Chunk 3
# install.packages("tmap")
library(tmap)
# Chunk 4
data(Europe)
qtm(Europe)
# Chunk 5
EUR <- Europe@data
# Chunk 7
kable(Europe@data[,1:4])
# Chunk 8
qtm(Europe, fill="gdp_cap_est")
# Chunk 9
qtm(Europe, fill="gdp_cap_est", text="iso_a3")
# Chunk 10
qtm(Europe, fill="gdp_cap_est", text="iso_a3",
text.size="AREA", root=5, fill.title="GDP per capita",
fill.textNA="Non-European countries", theme="Europe")
# Chunk 11
qtm(Europe, fill="pop_est_dens",
fill.title="Population density")
# Chunk 12
library(XML)
info <- colnames(Europe@data)
info_df <- data.frame(Europe@data)
kable(info_df[1:8,1:6])
# Chunk 13
link <- "http://userpage.chemie.fu-berlin.de/diverse/doc/ISO_3166.html"
Tab <- readHTMLList(link)
Tab <- strsplit(x = Tab[[1]],split = "\n")
Tab3 <- Tab[[3]]
Tab4 <- Tab3[-c(1:7)]
Tab4
# Chunk 14
qtm(Europe, fill="continent")
# Chunk 15
qtm(Europe, fill="part",fill.title="part of Europe")
# Chunk 16
qtm(Europe, fill="area") # Russia is huge
# Chunk 17
qtm(Europe, fill="pop_est",fill.title="Population")
# Chunk 18
qtm(Europe, fill="pop_est_dens",
fill.title="Population density")
# Chunk 19
qtm(Europe, fill="economy")
# Chunk 20
qtm(Europe, fill="income_grp",fill.title="Income group")
# Chunk 22
data(World)
kable(World@data[1:15,])
# Chunk 23
qtm(World, fill="income_grp",fill.title="Income group")
# Chunk 25
data(NLD_prov)
NLD_df <- NLD_prov@data
kable(head(NLD_df))
# Chunk 26
qtm(NLD_prov, fill="population",fill.title="population")
# Chunk 27
pop <- NLD_prov@data$population
pop
# Chunk 28
popmen <- NLD_prov@data$pop_men
popmen
# Chunk 29
prop <- popmen/pop
prop
# Chunk 31
barplot(prop,col="blue")
# Chunk 32
NLD_prov@data$proportion <- prop
# Chunk 33
qtm(NLD_prov, fill="proportion",fill.title="proportion")
# Chunk 34
ant <- runif(length(NLD_prov),.18,.28)
NLD_prov@data$pop_65plus <-
round(NLD_prov@data$population*ant)
pop65plus <- NLD_prov@data$pop_65plus
prop65plus <- pop65plus/pop
NLD_prov@data$proportion65plus <- prop65plus
# Chunk 35
qtm(NLD_prov, fill="proportion",fill.title="proportion")
# Chunk 36
data(NLD_muni)
# Chunk 38
NLD_df <- NLD_muni@data
NLD_df[,6] <- round(NLD_df[,6])
kable(NLD_df[,c("name","province","population")])
# Chunk 39
qtm(NLD_muni, fill="population")
# Chunk 40
tm_shape(Europe) +
tm_fill(c("pop_est_dens", "gdp_cap_est"),
title=c("Population density", "GDP per capita"))
# + tm_layout_Europe()
data(land)
info_df <- land@data[1:100,]
datatable(info_df)
data(land)
info_df <- land@data[1:15,]
kable(info_df)
info_df <- land@data[sample(1:length(land),10,replace=T),]
kable(info_df)
tm_shape(land,  relative=FALSE) +
tm_raster(title="Global Land Cover")
?tm_raster
tm_shape(land,  relative=FALSE) +
tm_raster("cover", title="Global Land Cover")
tm_shape(land,  relative=FALSE) +
tm_raster("trees", title="Global Land Cover")
head(land)
head(info_df)
?land
kable(Unemp[1:8,c(2,3,4,5)])
url <- "https://raw.githubusercontent.com/Japhilko/
GeoData/master/2015/data/Unemployment07a13.csv"
Unemp <- read.csv(url)
kable(Unemp[1:10,c(2,3,4,5)])
Unemp
kable(Unemp[1:10,])
qtm(Europe, fill="gdp_cap_est", text="iso_a3",
text.size="AREA", fill.title="GDP per capita",
fill.textNA="Non-European countries", theme="Europe")
head(Europe@data)
tm_shape(Europe) +
tm_fill(c("pop_est", "economy"),
title=c("Population", "Economy"))
kable(info_df[,1:2])
kable(info_df[,c(1,3)])
kable(info_df[,c(2,3)])
